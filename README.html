<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Toni Verbeiren, Data Intuitive" />
  <title>DiFlow</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="/Users/toni/Dropbox/_Tools/Stylesheets/Pandoc/bootstrap-html/template.css" />
</head>
<body>
    <div class="navbar navbar-static-top">
    <div class="navbar-inner">
      <div class="container">
        <span class="doc-title">DiFlow</span>
        <ul class="nav pull-right doc-info">
                    <li><p class="navbar-text">Toni Verbeiren, Data Intuitive</p></li>
                              <li><p class="navbar-text">Tuesday - October 06, 2020</p></li>
                  </ul>
      </div>
    </div>
  </div>
    <div class="container">
    <div class="row">
            <div id="TOC" class="span3">
        <div class="well toc">
        <ul>
          <li class="nav-header">Table of Contents</li>
        </ul>
        <ul>
        <li><a href="#introduction">Introduction</a>
        <ul>
        <li><a href="#functional-reactive-programming-frp">Functional Reactive Programming (FRP)</a></li>
        <li><a href="#frp-for-pipelines">FRP for pipelines</a></li>
        </ul></li>
        <li><a href="#nextflow">NextFlow</a>
        <ul>
        <li><a href="#frp-in-nextflow">FRP in NextFlow</a></li>
        <li><a href="#nextflow-dsl2">NextFlow DSL(2)</a></li>
        </ul></li>
        <li><a href="#diflow">DiFlow</a>
        <ul>
        <li><a href="#the-nopipeline-approach">The NoPipeline approach</a></li>
        <li><a href="#general-requirements-and-design-principles">General Requirements and design principles</a>
        <ul>
        <li><a href="#reproducibility">Reproducibility</a></li>
        <li><a href="#pipeline-parameters-vs-runtime-parameters">Pipeline Parameters vs Runtime Parameters</a></li>
        <li><a href="#consistent-api">Consistent API</a></li>
        <li><a href="#flat-module-structure">Flat Module Structure</a></li>
        <li><a href="#job-serialization">Job Serialization</a></li>
        </ul></li>
        <li><a href="#an-abstract-computation-step">An abstract computation step</a></li>
        <li><a href="#toward-implementation">Toward implementation</a></li>
        </ul></li>
        <li><a href="#step-by-step">Step by step</a>
        <ul>
        <li><a href="#poc1">POC1</a></li>
        <li><a href="#poc2">POC2</a></li>
        <li><a href="#poc3">POC3</a></li>
        <li><a href="#poc4">POC4</a></li>
        <li><a href="#poc5">POC5</a></li>
        <li><a href="#poc6">POC6</a></li>
        <li><a href="#poc7">POC7</a></li>
        <li><a href="#poc8">POC8</a></li>
        <li><a href="#poc9">POC9</a></li>
        <li><a href="#poc10">POC10</a></li>
        <li><a href="#poc11">POC11</a></li>
        <li><a href="#poc12">POC12</a></li>
        <li><a href="#poc13">POC13</a></li>
        <li><a href="#poc14">POC14</a></li>
        <li><a href="#poc15">POC15</a></li>
        </ul></li>
        <li><a href="#appendix">Appendix</a>
        <ul>
        <li><a href="#caveats-and-tips">Caveats and Tips</a>
        <ul>
        <li><a href="#section"></a></li>
        <li><a href="#resources">Resources</a></li>
        <li><a href="#default-values">Default values</a></li>
        <li><a href="#target_image"><code>target_image</code></a></li>
        <li><a href="#running-the-docker-setup">Running the Docker setup</a></li>
        </ul></li>
        <li><a href="#open-issues">Open issues</a></li>
        </ul></li>
        </ul>
        </div>
      </div>
            <div class="span9">
            <h1 id="introduction">Introduction</h1>
            <p><a href="https://pointer">DiFlow</a> is an abstraction layer on top of <a href="https://www.nextflow.io/">NextFlow</a>’s <a href="https://www.nextflow.io/docs/latest/dsl2.html">DSL2</a>. DiFlow is a set of principles and guidelines for building NextFlow pipelines that allow the developer to declaratively define processing components and the user to declare the pipeline logic in a clean and intuitive way.</p>
            <p><a href="http://data-intuitive.com/viash_docs">Viash</a> is a tool that (among other things) allows us to <em>use</em> DiFlow and make it practical, without the burden of maintaining boilerplate or <em>glue</em> code.</p>
            <h2 id="functional-reactive-programming-frp">Functional Reactive Programming (FRP)</h2>
            <p>If you’re new to Functional Reactive Programming (FRP), here are a few pointers to posts and a video that introduce the concepts:</p>
            <ul>
            <li>An excellent <a href="https://itnext.io/demystifying-functional-reactive-programming-67767dbe520b">Medium post</a> from Timo Stöttner</li>
            <li>The <a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754">introduction</a> to Reactive Programming you’ve been missing from André Staltz.</li>
            <li>A very insightful <a href="https://www.youtube.com/watch?v=fdol03pcvMA">presentation</a> by Staltz where he introduces FRP from first principles (with live coding).</li>
            </ul>
            <p>In what follows, we will refer to <em>streams</em> in line with those authors but if you’re used to working with <a href="http://reactivex.io/">Rx</a> you would call this an observable.</p>
            <h2 id="frp-for-pipelines">FRP for pipelines</h2>
            <p>Other initiatives have consideren that FRP is a good fit for pipeline development. Recent research and development also confirms this<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
            <h1 id="nextflow">NextFlow</h1>
            <h2 id="frp-in-nextflow">FRP in NextFlow</h2>
            <p>The <a href="https://www.nextflow.io/docs/latest/channel.html"><code>Channel</code></a> class used by NextFlow, itself based on the <a href="https://en.wikipedia.org/wiki/Dataflow_programming">DataFlow Programming Model</a> can in fact be regarded as an implementation of a Functional Reactive Programming library. Having said that, NextFlow allows one to to mix functional and imperative programming to the point that a developer is able to shoot its own foot.</p>
            <p>Furthermore, <code>Channel</code>s can not be nested which complicates certain operations on the streams.</p>
            <h2 id="nextflow-dsl2">NextFlow DSL(2)</h2>
            <p><a href="https://www.nextflow.io/docs/latest/dsl2.html">DSL2</a> is a crucial development in NextFlow because it avoid having to maintain large, monolithic pipeline definitions in one file. With DSL2, developer can spin off functionality in separate files and <code>import</code> what is needed.</p>
            <p>This also potentially opens up ways to build (reusable) modules that could be used in different projects. That is exactly what a lot of organizations need.</p>
            <h1 id="diflow">DiFlow</h1>
            <h2 id="the-nopipeline-approach">The NoPipeline approach</h2>
            <p>For developing the pipeline, we set out with a few goals in mind:</p>
            <ul>
            <li>Build modules where each modules deals with a specific (computational) task</li>
            <li>Make sure those modules can be reused</li>
            <li>Make sure the module functionality can be tested and validated</li>
            <li>Make sure modules have a consistent API, so that
            <ol type="a">
            <li>calling a module is straightforward</li>
            <li>including a module in a pipeline is transparent and seamless</li>
            </ol></li>
            </ul>
            <p>Please note that nothing in these requirements has to do with running a pipeline itself. Rather, we consider this a bottom-up system whereby we first focus on a solid foundation before we actually start to tie things together.</p>
            <p>That’s why we call this the NoPipeline approach, similar to NoSQL where ‘No’ does not stand for <em>not</em>, but rather ‘Not Only’. The idea is to focus on the pipeline aspect <em>after</em> the steps are properly defined and tested.</p>
            <h2 id="general-requirements-and-design-principles">General Requirements and design principles</h2>
            <h3 id="reproducibility">Reproducibility</h3>
            <p>I originally did not include it as a design principle for the simple reason that I think it’s obvious. This should be every researcher’s top priority.</p>
            <h3 id="pipeline-parameters-vs-runtime-parameters">Pipeline Parameters vs Runtime Parameters</h3>
            <p>We make a strict distinction between parameters that are defined for the <em>FULL</em> pipeline and those that are defined at runtime.</p>
            <h4 id="pipeline-parameters">Pipeline Parameters</h4>
            <p>We currently have 4 pipeline parameters: Docker prefix, <code>ddir</code>, <code>rdir</code> and <code>pdir</code>.</p>
            <h4 id="runtime-parameters">Runtime Parameters</h4>
            <p>Runtime parameters differ from pipeline parameters in that they may be different for parallel runs of a process. A few examples:</p>
            <ul>
            <li>Some samples may require different filter threshold than others</li>
            <li>After concatenation, clustering may be run with different cluster parameters</li>
            <li>etc.</li>
            </ul>
            <p>In other words, it does not make sense to define those parameters for the full pipeline because they are not static.</p>
            <h3 id="consistent-api">Consistent API</h3>
            <p>When we started out with the project and chose to use NextFlow as a workflow engine, I kept on thinking that the level of abstraction should have been higher. With DSL1, all you could do was create one long list of NextFlow code, tied together by <code>Channel</code>s.</p>
            <p>With DSL2, it became feasible to <em>organise</em> stuff in separate NextFlow files and import what is required. But in larger codebases, this is not really a benefit because every modules/workflow may have its own parameters and output. No structure is imposed. <code>Workflow</code>s are basically functions taking parameters in and returning values.</p>
            <p>I think it makes sense to define an API and to stick to it as much as possible. This makes using the modules/workflows easier…</p>
            <h3 id="flat-module-structure">Flat Module Structure</h3>
            <p>We want to avoid having nested modules, but rather support a pool of modules to be mixed and matched.</p>
            <p>As a consequence, this allows a very low threshold for including third-party modules: just add it to the collection of modules and import it in the pipeline. In order to facilitate the inclusion of such third-party modules that are developed in their own respective repositories, we added one additional layer in the hierarchy allowing for such a splitting.</p>
            <h3 id="job-serialization">Job Serialization</h3>
            <p>We avoid requiring the sources of the job available in the runtime environment, i.e., the Docker container. In other words, all code and config is serialized and sent with the <em>process</em>.</p>
            <h2 id="an-abstract-computation-step">An abstract computation step</h2>
            <p>The module concept inspired us to think of an abstract way to represent a computation step and implement this in NextFlow. We wrote [Portash] to this end. But Portash had its shortcomings. The most important of which was that it did not adhere to separation of concerns: execution definition (what?) where mixed up with execution context (how?/where?). Moreover, dynamic nature of Portash lends itself well to running a tool as a service, but not so much in a batch process.</p>
            <p>Nevertheless, we were able to express a generic NextFlow step as pure <em>configuration</em> that is passed to a process at runtime. This allows for some very interesting functionality. Some prototypes were developed, the last one of which could run a single-cell RNA pipeline from mapping to generating an integrated dataset combining different samples.</p>
            <p>The run-configuration was provided by means of a Portash YAML spec residing in the module directory. It must be stressed that not requiring the component <em>code</em> to be already available inside the container is a big plus. It means a container contains dependencies, not the actual run script so the latter can be updated more frequently. This is especially useful during component and pipeline development.</p>
            <p>Our first implementation had a few disadvantages:</p>
            <ul>
            <li>It contained a mix of what to run and how to run it, but it did not contain information on the container to run in. This had to be configured externally, but then the module is not an independent entity anymore.</li>
            <li>Specifying and overriding YAML content in Groovy is possible, but not something that is intuitive. We worked around that by letting the user specify custom configuration using a Groovy nested <code>Map</code>.</li>
            <li>The module functionality was abstracted with a consistent API and the difference between 2 modules was just a few lines of code with a different name or pointer. But still, one had to maintain that and making a similar change in a growing set of module files is a recipe for mistakes.</li>
            </ul>
            <p>But overall, the concept of an abstract computation step proved to work, it was just that a few ingredients were still missing it seemed. On the positive side, we showed that it’s possible to have an abstract API for (NextFlow) modules that keeps the underlying implementation hidden while improving the readability of the pipeline code.</p>
            <h2 id="toward-implementation">Toward implementation</h2>
            <p>What is needed as information in order to run a computation step in a pipeline?</p>
            <ol type="1">
            <li><p>First, we need data or generally speaking, <strong>input</strong>. Components/modules and pipelines should run zero-touch, so input has to be provided at startup time.</p></li>
            <li><p>Secondly, we need to know what to run en how to run it. This is in effect the definition of a modules or pipeline step.</p></li>
            <li><p>Thirdly, in many cases we will require the possibility to change parameters for individual modules in the pipeline, for instance cutoff values for a filter, or the number of clusters for a clustering algorithm. The classical way to do that is via the <code>params</code> object.</p></li>
            </ol>
            <p>One might wonder if there is a difference between input and parameters pointing to input is also a kind of parametrization. The reason those are kept apart is that additional validation steps are necessary for the data. Most pipeline systems trace input/output closely whereas parameters are ways to configure the steps in the pipeline.</p>
            <p>In terms of FRP, and especially in the DataFlow model, we also have to keep track of the <em>forks</em> in a parallel execution scenario. For instance, if 10 batches of data can be processed in parallel we should give all 10 of them an ID so that individual forks can be distinguished. We will see that those IDs become crucial in most pipelines.</p>
            <p>We end up with a model for a stream/channel as follows (conceptually):</p>
            <pre><code>[ ID, data, config ]</code></pre>
            <p>were</p>
            <ul>
            <li><code>ID</code> is just a string or any object for that matter that can be compared later. We usually work with strings.</li>
            <li><code>data</code> is a pointer to the (input) data. With NextFlow, this should be a <code>Path</code> object, ideally created using the <code>file()</code> helper function.</li>
            <li><code>config</code> is a nested <code>Map</code> where the first level keys are chosen to be simply an identifier of the pipeline step. Other approaches can be taken here, but that’s what we did.</li>
            </ul>
            <p>This can be a triplet, or a list with mixed types. In Groovy, both can be used interchangeably.</p>
            <p>The output of a pipeline step/mudules adheres to the same structure so that pipeline steps can easily be chained.</p>
            <h1 id="step-by-step">Step by step</h1>
            <p>Let us illustrate some key features of NextFlow together with how we use them in DiFlow.</p>
            <h2 id="poc1">POC1</h2>
            <p>Let us illustrate the stream-like nature of a NXF <code>Channel</code> using a very simple example: computing <span class="math inline">1 + 1</span>.</p>
            <pre class="groovy"><code>workflow poc1 {

                Channel.from(1) \
                    | map{ it + 1 } \
                    | view{ it }

            }</code></pre>
            <p>This chunk is directly taken from <code>main.nf</code>, running it can be done as follows:</p>
            <div class="sourceCode" id="cb3"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="ex">nextflow</span> run . -entry poc1</span></code></pre></div>
            <h2 id="poc2">POC2</h2>
            <p>NextFlow (and streams in general) are supposed to be a good fit for parallel execution. Let’s see how this can be done:</p>
            <pre class="groovy"><code>workflow poc2 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ it + 1 } \
                    | view{ it }

            }</code></pre>
            <p>Running it can be done using:</p>
            <div class="sourceCode" id="cb5"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="ex">nextflow</span> run . -entry poc3</span></code></pre></div>
            <h2 id="poc3">POC3</h2>
            <p>In the previous example, we ran 3 parallel executions each time applying the same simple function: adding one. Let us simulate now a more real-life example where parallel executions will not take the same amount of time. We do this by defining a <code>process</code> and <code>workflow</code> that uses this process. The rest is similar to our example before.</p>
            <pre class="groovy"><code>process add {

                input:
                    val(input)
                output:
                    val(output)
                exec:
                    output = input + 1

            }

            workflow poc3 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | add \
                    | view{ it }

            }</code></pre>
            <p>Running it is again the same.</p>
            <div class="sourceCode" id="cb7"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1"></a><span class="ex">nextflow</span> run . -entry poc3</span></code></pre></div>
            <p>The result will be a permutation of 2,3 and 4. Try it multiple times to verify for yourself that the order is not guaranteed to be the same. Even though the execution times will not be that much different! In other words, a <code>Channel</code> does not guarantee the order, and that’s a good thing.</p>
            <h2 id="poc4">POC4</h2>
            <p>An illustrative test is one where we do not use a <code>process</code> for the execution, but rather just <code>map</code> but such that one of the inputs <em>takes longer</em> to process, i.e.:</p>
            <pre class="groovy"><code>def waitAndReturn(it) { sleep(2000); return it }

            workflow poc4 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ (it == 2) ? waitAndReturn(it) : it } \
                    | map{ it + 1 } \
                    | view{ it }

            }</code></pre>
            <p>Running it:</p>
            <div class="sourceCode" id="cb9"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1"></a><span class="ex">nextflow</span> run . -entry poc4</span></code></pre></div>
            <p>The result may be somewhat unexpected, the order is retained there’s just a 2 second delay between the first entry and the rest. The <code>sleep</code> in other words blocks all the parallel execution branches.</p>
            <p>This is a clear indication of why it’s better to use a <code>process</code> to execute computations. On the other hand, as long as we <em>stay</em> inside the <code>map</code> and don’t run a <code>process</code>, the order is the same. This opens up some possibilities that we will exploit in what follows.</p>
            <h2 id="poc5">POC5</h2>
            <p>If we can not guarantee the order of the different parallel branches, we should introduce a <em>branch ID</em>. This may be a label, a sample ID, a batch ID, etc. It’s the unit of parallelization.</p>
            <pre><code>process addTuple {

                input:
                    tuple val(id), val(input)
                output:
                    tuple val(&quot;${id}&quot;), val(output)
                exec:
                    output = input + 1

            }

            workflow poc5 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el ]} \
                    | addTuple \
                    | view{ it }

            }</code></pre>
            <p>We can ran this code sample in the same way as the previous examples.</p>
            <p>Please note that the function to add 1 remains exactly the same, we only added the <code>id</code> as the first element of the tuple in both input and output. As such we keep a handle on which sample is which, by means of the <em>key</em> in the tuple.</p>
            <p>Note: Later, we will extend this tuple and add configuration parameters to it… but this was supposed to go step by step.</p>
            <h2 id="poc6">POC6</h2>
            <p>What if we want to be able to configure the term in the sum? This would require a parameter to be sent with the process invocation. Let’s see how this can be done.</p>
            <pre class="groovy"><code>
            process addTupleWithParameter {

            input:
                tuple val(id), val(input), val(term)
            output:
                tuple val(&quot;${id}&quot;), val(output)
            exec:
                output = input + term

            }

            workflow poc6 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, 10 ]} \
                    | addTupleWithParameter \
                    | view{ it }

            }</code></pre>
            <p>This works, but is not very flexible. What if we want to configure the operator as well? What if we want to have branch-specific configuration? We can add a whole list of parameters, but that means that the <code>process</code> signature may be different for every <code>process</code> that we define. That is not a preferred solution.</p>
            <h2 id="poc7">POC7</h2>
            <p>Let us use a simple hash to add 2 configuration parameters.</p>
            <pre class="groovy"><code>process addTupleWithHash {

                input:
                    tuple val(id), val(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), val(output)
                exec:
                    output = (config.operator == &quot;+&quot;) ? input + config.term : input - config.term

            }

            workflow poc7 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, [ &quot;operator&quot; : &quot;-&quot;, &quot;term&quot; : 10 ]  ]} \
                    | addTupleWithHash \
                    | view{ it }

            }</code></pre>
            <h2 id="poc8">POC8</h2>
            <p>POC7 offers us a way to use a consistent API for a process. Ideally, however, we would like different <code>process</code> invocation to be chained rather than to explicitly add the correct configuration all the time. Let us add an additional key to the map, so that a process knows <em>it’s scope</em>.</p>
            <pre class="groovy"><code>process addTupleWithProcessHash {

                input:
                    tuple val(id), val(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), val(output)
                exec:
                    def thisConf = config.addTupleWithProcessHash
                    output = (thisConf.operator == &quot;+&quot;) ? input + thisConf.term : input - thisConf.term

            }

            workflow poc8 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, [ &quot;addTupleWithProcessHash&quot; : [ &quot;operator&quot; : &quot;-&quot;, &quot;term&quot; : 10 ] ] ] } \
                    | addTupleWithProcessHash \
                    | view{ it }

            }</code></pre>
            <p>Please note that we used the process name as a key in the map, so that each process can tell what configuration parameter are relevant for its own scope.</p>
            <h2 id="poc9">POC9</h2>
            <p>We used native Groovy code in the <code>process</code> examples above. Let us now use a shell script:</p>
            <pre class="groovy"><code>workflow poc8 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, [ &quot;addTupleWithProcessHash&quot; : [ &quot;operator&quot; : &quot;-&quot;, &quot;term&quot; : 10 ] ] ] } \
                    | addTupleWithProcessHash \
                    | view{ it }

            }

            process addTupleWithProcessHashScript {

                input:
                    tuple val(id), val(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), stdout
                script:
                    def thisConf = config.addTupleWithProcessHashScript
                    def operator = thisConf.operator
                    def term = thisConf.term
                    &quot;&quot;&quot;
                    echo \$( expr $input $operator ${thisConf.term} )
                    &quot;&quot;&quot;

            }</code></pre>
            <p>Running this (in the same way as before), we get something along these lines:</p>
            <pre><code>[3, -7
            ]
            [1, -9
            ]
            [2, -8
            ]</code></pre>
            <p>This is because the <code>stdout</code> qualifier captures the newline at the end of the code block. We could look for ways to circumvent that, but that is not the point here.</p>
            <p>What’s important to notice here:</p>
            <ol type="1">
            <li>We can not just retrieve individual entries in <code>config</code> in the shell, we have to let Groovy do that.</li>
            <li>That means we either first retrieve individual values and store them in a variable,</li>
            <li>or we use the <code>${...}</code> notation for that.</li>
            <li>If we want to use <code>bash</code> variables, the <code>$</code> symbol has to be escaped.</li>
            </ol>
            <p>Obviously, passing config like this requires a lot of typing (especially as additional parameters are introduced) and is error prone.</p>
            <h2 id="poc10">POC10</h2>
            <p>We used the pipe <code>|</code> symbol to combine different steps in a <em>pipeline</em> and we noticed that a <code>process</code> can do computations on parallel branches. That’s nice, but we have not yet given an example of running 2 processes, one after the other.</p>
            <p>There are a few things we have to note before we go to an example:</p>
            <ol type="1">
            <li>It’s not possible to call the same process twice, a strange error occurs in that case<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</li>
            <li>If we want to pipe the output of one process as input of the next, the I/O signature needs to be exactly the same, so the <code>output</code> of the <code>process</code> should be a triplet as well.</li>
            </ol>
            <pre class="groovy"><code>process process_poc10a {

                input:
                    tuple val(id), val(input), val(term)
                output:
                    tuple val(&quot;${id}&quot;), val(output), val(&quot;${term}&quot;)
                exec:
                    output = input.toInteger() + term.toInteger()

            }

            process process_poc10b {

                input:
                    tuple val(id), val(input), val(term)
                output:
                    tuple val(&quot;${id}&quot;), val(output), val(&quot;${term}&quot;)
                exec:
                    output = input.toInteger() - term.toInteger()

            }

            workflow poc10 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, 10 ] } \
                    | process_poc10a \
                    | process_poc10b \
                    | view{ it }

            }</code></pre>
            <p>The result of this is that first 10 is added and then the same 10 is subtracted again, which results in the same as the original. Please note that the output contains 3 elements, also the <code>term</code> passed to the <code>process</code>:</p>
            <pre><code>[3, 3, 10]
            [1, 1, 10]
            [2, 2, 10]</code></pre>
            <p>We can configure the second <code>process</code> (subtraction) by adding an additional <code>map</code> in the mix:</p>
            <pre class="groovy"><code>workflow poc10 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, 10 ] } \
                    | process_poc10a \
                    | map{ [ it[0], it[1], 5 ] } \
                    | process_poc10b \
                    | view{ it }

            }</code></pre>
            <p>Please note that we define the closure in a different manner here, using the special variable <code>it</code>. We could also write (to the same effect):</p>
            <pre class="groovy"><code>        ...
                    | map{ x -&gt; [ x[0], x[1], 5 ] } \
                    ...</code></pre>
            <p>or even</p>
            <pre class="groovy"><code>        ...
                    | map{ id, value, term -&gt; [ id, value, 5 ] } \
                    ...</code></pre>
            <h2 id="poc11">POC11</h2>
            <p>What if we rewrite the previous using some of the techniques introduced earlier. Let us specify the operator as a parameter and try to stick to just 1 <code>process</code> definition.</p>
            <pre class="groovy"><code>process process_poc11 {

                input:
                    tuple val(id), val(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), val(output), val(&quot;${config}&quot;)
                exec:
                    if (config.operator == &quot;+&quot;)
                       output = input.toInteger() + config.term.toInteger()
                    else
                       output = input.toInteger() - config.term.toInteger()

            }

            workflow poc11 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, [ &quot;term&quot; : 10, &quot;operator&quot; : &quot;+&quot; ] ] } \
                    | process_poc11 \
                    | map{ id, value, term -&gt; [ el.toString(), el, [ &quot;term&quot; : 11, &quot;operator&quot; : &quot;-&quot; ] ] } \
                    | process_poc11 \
                    | view{ it }

            }</code></pre>
            <p>This little workflow definition results in an error, just like we warned before:</p>
            <div class="sourceCode" id="cb22"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1"></a>$ <span class="ex">nextflow</span> run . -entry poc11</span>
            <span id="cb22-2"><a href="#cb22-2"></a><span class="ex">N</span> E X T F L O W  ~  version 19.10.0</span>
            <span id="cb22-3"><a href="#cb22-3"></a><span class="ex">Launching</span> <span class="kw">`</span><span class="ex">./main.nf</span><span class="kw">`</span> [distracted_hilbert] - revision: 1445a8ce0c</span>
            <span id="cb22-4"><a href="#cb22-4"></a><span class="ex">WARN</span>: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE</span>
            <span id="cb22-5"><a href="#cb22-5"></a><span class="ex">assert</span> processConfig==null</span>
            <span id="cb22-6"><a href="#cb22-6"></a>       <span class="kw">|</span></span>
            <span id="cb22-7"><a href="#cb22-7"></a>       [<span class="st">&#39;echo&#39;</span>:<span class="ex">false</span>, <span class="st">&#39;cacheable&#39;</span>:true, <span class="st">&#39;shell&#39;</span>:[<span class="st">&#39;/bin/bash&#39;</span>, <span class="st">&#39;-ue&#39;</span>], <span class="st">&#39;validExitStatus&#39;</span>:[0], <span class="st">&#39;maxRetries&#39;</span>:0, <span class="st">&#39;maxErrors&#39;</span>:-1, <span class="st">&#39;errorStrategy&#39;</span>:TERMINATE]</span>
            <span id="cb22-8"><a href="#cb22-8"></a></span>
            <span id="cb22-9"><a href="#cb22-9"></a> <span class="ex">--</span> Check script <span class="st">&#39;main.nf&#39;</span> at line: 209 or see <span class="st">&#39;.nextflow.log&#39;</span> file for more details</span></code></pre></div>
            <p>There is, however, one simple way around this: <code>include ... as ..</code>. Let us see how this works.</p>
            <p>First, we store the <code>process</code> in a file <code>examples/poc/poc11.nf</code>:</p>
            <pre class="groovy"><code>process process_poc11 {

                input:
                    tuple val(id), val(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), val(output), val(&quot;${config}&quot;)
                exec:
                    if (config.operator == &quot;+&quot;)
                       output = input.toInteger() + config.term.toInteger()
                    else
                       output = input.toInteger() - config.term.toInteger()

            }</code></pre>
            <p>The <code>workflow</code> definition becomes:</p>
            <pre class="groovy"><code>include process_poc11 as process_poc11a from &#39;./examples/poc/poc11.nf&#39;
            include process_poc11 as process_poc11b from &#39;./examples/poc/poc11.nf&#39;

            workflow poc11 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, [ : ] ] } \
                    | map{ id, value, config -&gt; [ id, value, [ &quot;term&quot; : 5, &quot;operator&quot; : &quot;+&quot; ] ] } \
                    | process_poc11a \
                    | map{ id, value, config -&gt; [ id, value, [ &quot;term&quot; : 11, &quot;operator&quot; : &quot;-&quot; ] ] } \
                    | process_poc11b \
                    | view{ [ it[0], it[1] ] }

            }</code></pre>
            <p>Running this yields an output similar to this:</p>
            <div class="sourceCode" id="cb25"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1"></a>$ <span class="ex">nextflow</span> run . -entry poc11</span>
            <span id="cb25-2"><a href="#cb25-2"></a><span class="ex">N</span> E X T F L O W  ~  version 19.10.0</span>
            <span id="cb25-3"><a href="#cb25-3"></a><span class="ex">Launching</span> <span class="kw">`</span><span class="ex">./main.nf</span><span class="kw">`</span> [sharp_gilbert] - revision: ee0b54f3d9</span>
            <span id="cb25-4"><a href="#cb25-4"></a><span class="ex">WARN</span>: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE</span>
            <span id="cb25-5"><a href="#cb25-5"></a><span class="ex">executor</span> <span class="op">&gt;</span>  local (6)</span>
            <span id="cb25-6"><a href="#cb25-6"></a>[<span class="ex">e3</span>/<span class="ex">aabcbc</span>] process <span class="op">&gt;</span> poc11:process_poc11a (3) [<span class="ex">100%</span>] 3 of 3</span>
            <span id="cb25-7"><a href="#cb25-7"></a>[<span class="ex">3e</span>/<span class="ex">ec7d8f</span>] process <span class="op">&gt;</span> poc11:process_poc11b (3) [<span class="ex">100%</span>] 3 of 3</span>
            <span id="cb25-8"><a href="#cb25-8"></a>[<span class="ex">2</span>, -4]</span>
            <span id="cb25-9"><a href="#cb25-9"></a>[<span class="ex">1</span>, -5]</span>
            <span id="cb25-10"><a href="#cb25-10"></a>[<span class="ex">3</span>, -3]</span></code></pre></div>
            <p>We made a few minor changes to the workflow code in the meanwhile:</p>
            <ol type="1">
            <li>Splitting the conversion from an array of items to the triplet is now done explicitly and separate from the specifying the configuration for the <code>process</code> itself.</li>
            <li>The <code>view</code> now only contains the relevant parts, not the configuration part for the last <code>process</code>.</li>
            </ol>
            <p>The above example illustrates the <code>include</code> functionality of NextFlow DSL2. This was not possible with prior versions.</p>
            <h2 id="poc12">POC12</h2>
            <p>Let’s implement a simple map/reduce schema with what we developed above. Until now, we basically covered the mapping stage: starting from 3 independent number, execute a function on each <em>branch</em> individually. Now, we want to calculate the sum at the end (reduce phase).</p>
            <p>We do this by adding a <code>process</code> to the example in POC10</p>
            <pre class="groovy"><code>process process_poc12 {

                input:
                    tuple val(id), val(input), val(term)
                output:
                    tuple val(&quot;${id}&quot;), val(output), val(&quot;${term}&quot;)
                exec:
                    output = input.sum()

            }

            workflow poc12 {

                Channel.from( [ 1, 2, 3 ] ) \
                    | map{ el -&gt; [ el.toString(), el, 10 ] } \
                    | process_poc10a \
                    | toList \
                    | map{ [ &quot;sum&quot;, it.collect{ id, value, config -&gt; value }, [ : ] ] } \
                    | process_poc12 \
                    | view{ [ it[0], it[1] ] }

            }</code></pre>
            <p>A few remarks are in order here:</p>
            <ol type="1">
            <li>We use the <code>toList</code> operator on the output of <code>process_poc10a</code>. This can be regarded as merging the 3 parallel branches into one branch. The result has the signature <code>Channel[List[Triplet]]</code>. This <code>toList</code> operator only <em>outputs</em> something on the output <code>Channel</code> when all incoming branches have finished and the <em>merge</em> can effectively be performed.</li>
            <li>It’s important to note that what is passed through the pipe is still a <code>Channel</code>, only the number of <em>branches</em>, <em>nodes</em>, or whatever you want to call it differs.</li>
            <li>The long <code>map{ [ "sum", ... }</code> line may seem complex at first, but it’s really not. We take in <code>List[Triplet]</code> and convert this to <code>Triplet</code>. The first element of the triplet is just an identifier (<code>sum</code>). The last is the configuration map, but we don’t need configuration for the sum. As the second element we want to obtain <code>List[Int]</code>, where the values are the 2nd element from the original triplets. The Groovy function <code>collect</code> on an array is like <code>map</code> in many other languages.</li>
            </ol>
            <p>The marble diagram can be depicted conceptually as follows, where we note that in effect it’s triplets rather than numbers that are contained in the marbles:</p>
            <p><img src="figures/poc12.png" style="width:30.0%" /></p>
            <p>Please note that though we define the <em>pipeline</em> sequentially, the 3 numbers are first handled in parallel and only combined when calling <code>toList</code>. Stated differently, parallelism comes for free when defining workflows like this.</p>
            <!--
            Marble spec, to be used on swirly.dev to reproduce the figure
            -abc-------------|
            a := 1
            b := 2
            c := 3

            > process_10a

            --def------------|
            d := 11
            e := 12
            f := 13

            > toList

            -----g-----------|
            g := [11, 12, 13]

            > process_poc12

            ------g----------|
            g := 36
            -->
            <h2 id="poc13">POC13</h2>
            <p>Let us tackle a different angle now and start to deal with files as input and output. In order to do this, we will mimic the functionality from earlier and modify it such that a file is used as input and output is also written to a file.</p>
            <p>The following combination of <code>process</code> and <code>workflow</code> definition does exactly the same as before, but now from one or more files containing just a single integer number:</p>
            <pre class="groovy"><code>process process_poc13 {

                input:
                    tuple val(id), file(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), file(&quot;output.txt&quot;), val(&quot;${config}&quot;)
                script:
                    &quot;&quot;&quot;
                    a=`cat $input`
                    let result=&quot;\$a + ${config.term}&quot;
                    echo &quot;\$result&quot; &gt; output.txt
                    &quot;&quot;&quot;

            }

            workflow poc13 {

                Channel.fromPath( params.input ) \
                    | map{ el -&gt; [ el.baseName.toString(), el, [ &quot;operator&quot; : &quot;-&quot;, &quot;term&quot; : 10 ]  ]} \
                    | process_poc13 \
                    | view{ [ it[0], it[1] ] }

            }</code></pre>
            <p>While doing this, we also introduced a way to specify parameters via a configuration file (<code>nextflow.config</code>) or from the CLI. In this case <code>params.input</code> points to an argument we should provide on the CLI, for instance:</p>
            <div class="sourceCode" id="cb28"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb28-1"><a href="#cb28-1"></a>$ <span class="ex">nextflow</span> run . -entry poc13 --input data/input1.txt</span>
            <span id="cb28-2"><a href="#cb28-2"></a><span class="ex">N</span> E X T F L O W  ~  version 19.10.0</span>
            <span id="cb28-3"><a href="#cb28-3"></a><span class="ex">Launching</span> <span class="kw">`</span><span class="ex">./main.nf</span><span class="kw">`</span> [gigantic_noether] - revision: 94d747c151</span>
            <span id="cb28-4"><a href="#cb28-4"></a><span class="ex">WARN</span>: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE</span>
            <span id="cb28-5"><a href="#cb28-5"></a><span class="ex">executor</span> <span class="op">&gt;</span>  local (1)</span>
            <span id="cb28-6"><a href="#cb28-6"></a>[<span class="ex">b1</span>/<span class="ex">57daf8</span>] process <span class="op">&gt;</span> poc13:process_poc13 (1) [<span class="ex">100%</span>] 1 of 1</span>
            <span id="cb28-7"><a href="#cb28-7"></a>[<span class="ex">input1</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/b1/57daf8f6a8ce6c1bc78f91c37cb466/output.txt]</span></code></pre></div>
            <p>Let’s dissect a bit what is going one here…</p>
            <ol type="1">
            <li>We provide the input file <code>data/input1.txt</code> as input which gets automatically added to the <code>params</code> map as <code>params.input</code>.</li>
            <li>The content of <code>input1.txt</code> is used in the simple sum just as before.</li>
            <li>The output <code>Channel</code> contains the known triplet but this time the second entry is not a value, but rather a filename.</li>
            </ol>
            <p>Please note that the file is <code>output.txt</code> is automatically stored in the unique <code>work</code> directory. We can take a look inside to verify that the calculation succeeded:</p>
            <div class="sourceCode" id="cb29"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1"></a>$ <span class="fu">cat</span> work/b1/57daf8f6a8ce6c1bc78f91c37cb466/output.txt</span>
            <span id="cb29-2"><a href="#cb29-2"></a><span class="ex">11</span></span></code></pre></div>
            <p>It seems the calculation went well, although one might be surprised by two things:</p>
            <ol type="1">
            <li>The output of the calculation is stored in some randomly generated <code>work</code> directory whereas we might want it somewhere more <em>findable</em>.</li>
            <li>The <code>process</code> itself defines the value of the output filename, which may seem odd… and it is.</li>
            </ol>
            <p>Taking our example a bit further and exploiting the fact that parallelism is natively supported by NextFlow as we’ve seen before, we can pass multiple input files to the same workflow defined above.</p>
            <div class="sourceCode" id="cb30"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1"></a>$ <span class="ex">nextflow</span> run . -entry poc13 --input <span class="st">&quot;</span><span class="va">$PWD</span><span class="st">/data/input*.txt&quot;</span></span>
            <span id="cb30-2"><a href="#cb30-2"></a><span class="ex">N</span> E X T F L O W  ~  version 19.10.0</span>
            <span id="cb30-3"><a href="#cb30-3"></a><span class="ex">Launching</span> <span class="kw">`</span><span class="ex">./main.nf</span><span class="kw">`</span> [peaceful_spence] - revision: 94d747c151</span>
            <span id="cb30-4"><a href="#cb30-4"></a><span class="ex">WARN</span>: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE</span>
            <span id="cb30-5"><a href="#cb30-5"></a><span class="ex">executor</span> <span class="op">&gt;</span>  local (3)</span>
            <span id="cb30-6"><a href="#cb30-6"></a>[<span class="ex">1c</span>/<span class="ex">a214c2</span>] process <span class="op">&gt;</span> poc13:process_poc13 (1) [<span class="ex">100%</span>] 3 of 3</span>
            <span id="cb30-7"><a href="#cb30-7"></a>[<span class="ex">input2</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/a6/7dee09b191837e67afa1139b20d525/output.txt]</span>
            <span id="cb30-8"><a href="#cb30-8"></a>[<span class="ex">input3</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/97/5261eeb055375d0779b1ee2645502c/output.txt]</span>
            <span id="cb30-9"><a href="#cb30-9"></a>[<span class="ex">input1</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/1c/a214c221285fc4b4e9ad65cc5c5b98/output.txt]</span></code></pre></div>
            <p>Please note that we</p>
            <ol type="1">
            <li>provide the absolute path to the file</li>
            <li>use a wildcard <code>*</code> to select multiple files</li>
            <li>enclose the path (with wildcard) in double quotes to avoid shell globbing.</li>
            </ol>
            <p>In the latter case, we end up with 3 output files, each named <code>output.txt</code> in their own respective (unique) <code>work</code> directory.</p>
            <h2 id="poc14">POC14</h2>
            <p>Let us tackle one of the pain points of the previous example: output files are hidden in the <code>work</code> directory. One might be tempted to specify an output file in the <code>process</code> definition as such <code>file("&lt;somepath&gt;/output.txt")</code> but when you try this, it will quickly turn out that this does not work in the long run (though it may work for some limited cases).</p>
            <p>NextFlow provides a better way to achieve the required functionality: <a href="https://www.nextflow.io/docs/latest/process.html?highlight=publish#publishdir"><code>publishDir</code></a>. Let us illustrate its use with an example again and just adding the <code>publishDir</code> directive:</p>
            <pre class="groovy"><code>process process_poc14 {

                publishDir &quot;output/&quot;

                input:
                    tuple val(id), file(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), file(&quot;output.txt&quot;), val(&quot;${config}&quot;)
                script:
                    &quot;&quot;&quot;
                    a=`cat $input`
                    let result=&quot;\$a + ${config.term}&quot;
                    echo &quot;\$result&quot; &gt; output.txt
                    &quot;&quot;&quot;

            }

            workflow poc14 {

                Channel.fromPath( params.input ) \
                    | map{ el -&gt; [ el.baseName.toString(), el, [ &quot;operator&quot; : &quot;-&quot;, &quot;term&quot; : 10 ]  ]} \
                    | process_poc14 \
                    | view{ [ it[0], it[1] ] }

            }</code></pre>
            <p>This single addition yields:</p>
            <div class="sourceCode" id="cb32"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1"></a>$ <span class="ex">nextflow</span> run . -entry poc14 --input data/input1.txt</span>
            <span id="cb32-2"><a href="#cb32-2"></a><span class="ex">N</span> E X T F L O W  ~  version 19.10.0</span>
            <span id="cb32-3"><a href="#cb32-3"></a><span class="ex">Launching</span> <span class="kw">`</span><span class="ex">./main.nf</span><span class="kw">`</span> [tiny_jones] - revision: 630950ba4c</span>
            <span id="cb32-4"><a href="#cb32-4"></a><span class="ex">WARN</span>: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE</span>
            <span id="cb32-5"><a href="#cb32-5"></a><span class="ex">executor</span> <span class="op">&gt;</span>  local (1)</span>
            <span id="cb32-6"><a href="#cb32-6"></a>[<span class="ex">2b</span>/<span class="ex">be1b41</span>] process <span class="op">&gt;</span> poc14:process_poc14 (1) [<span class="ex">100%</span>] 1 of 1</span>
            <span id="cb32-7"><a href="#cb32-7"></a>[<span class="ex">input1</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/2b/be1b41b70db8a855bfb8f17a300796/output.txt]</span>
            <span id="cb32-8"><a href="#cb32-8"></a></span>
            <span id="cb32-9"><a href="#cb32-9"></a>$ <span class="fu">cat</span> output/output.txt</span>
            <span id="cb32-10"><a href="#cb32-10"></a><span class="ex">11</span></span></code></pre></div>
            <p>This example shows us a powerful approach to publishing data during our at the end of a pipeline. There is a similar drawback as for the output filenames, however, and that is that the <code>process</code> defines the output directory explicitly. But there is a different problem as well which can be observed when running on multiple input files:</p>
            <div class="sourceCode" id="cb33"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1"></a>$ <span class="ex">nextflow</span> run . -entry poc14 --input <span class="st">&quot;</span><span class="va">$PWD</span><span class="st">/data/input*.txt&quot;</span></span>
            <span id="cb33-2"><a href="#cb33-2"></a><span class="ex">N</span> E X T F L O W  ~  version 19.10.0</span>
            <span id="cb33-3"><a href="#cb33-3"></a><span class="ex">Launching</span> <span class="kw">`</span><span class="ex">./main.nf</span><span class="kw">`</span> [exotic_thompson] - revision: 630950ba4c</span>
            <span id="cb33-4"><a href="#cb33-4"></a><span class="ex">WARN</span>: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE</span>
            <span id="cb33-5"><a href="#cb33-5"></a><span class="ex">executor</span> <span class="op">&gt;</span>  local (3)</span>
            <span id="cb33-6"><a href="#cb33-6"></a>[<span class="ex">3b</span>/<span class="ex">007268</span>] process <span class="op">&gt;</span> poc14:process_poc14 (1) [<span class="ex">100%</span>] 3 of 3</span>
            <span id="cb33-7"><a href="#cb33-7"></a>[<span class="ex">input3</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/82/7ec0f8d6106b1d4d61a2cb64797e74/output.txt]</span>
            <span id="cb33-8"><a href="#cb33-8"></a>[<span class="ex">input2</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/53/e25634a6bdd1613837a07cc7234617/output.txt]</span>
            <span id="cb33-9"><a href="#cb33-9"></a>[<span class="ex">input1</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/3b/0072687d416807b80cdca62aa7ab41/output.txt]</span>
            <span id="cb33-10"><a href="#cb33-10"></a></span>
            <span id="cb33-11"><a href="#cb33-11"></a>$ <span class="fu">cat</span> output/output.txt</span>
            <span id="cb33-12"><a href="#cb33-12"></a><span class="ex">11</span></span></code></pre></div>
            <p>What do you think happens here? Yes, sure, we <em>publish</em> the same <code>output.txt</code> file three times and each time overwriting the same file. The last one is the one that persists.</p>
            <h2 id="poc15">POC15</h2>
            <p>Let us describe a way to avoid the above issue. There are other approaches to resolve this issue, but let us for the moment look at one that can easily be reused.</p>
            <pre class="groovy"><code>process process_poc15 {

                publishdir &quot;output/${config.id}&quot;

                input:
                    tuple val(id), file(input), val(config)
                output:
                    tuple val(&quot;${id}&quot;), file(&quot;output.txt&quot;), val(&quot;${config}&quot;)
                script:
                    &quot;&quot;&quot;
                    a=`cat $input`
                    let result=&quot;\$a + ${config.term}&quot;
                    echo &quot;\$result&quot; &gt; output.txt
                    &quot;&quot;&quot;

            }

            workflow poc15 {

                channel.frompath( params.input ) \
                    | map{ el -&gt; [ el.basename.tostring(), el, [ &quot;id&quot;: el.basename, &quot;operator&quot; : &quot;-&quot;, &quot;term&quot; : 10 ]  ]} \
                    | process_poc15 \
                    | view{ [ it[0], it[1] ] }

            }</code></pre>
            <p>This results in the following:</p>
            <div class="sourceCode" id="cb35"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb35-1"><a href="#cb35-1"></a>$ <span class="ex">nextflow</span> run . -entry poc15 --input <span class="st">&quot;</span><span class="va">$PWD</span><span class="st">/data/input*.txt&quot;</span></span>
            <span id="cb35-2"><a href="#cb35-2"></a><span class="ex">N</span> E X T F L O W  ~  version 19.10.0</span>
            <span id="cb35-3"><a href="#cb35-3"></a><span class="ex">Launching</span> <span class="kw">`</span><span class="ex">./main.nf</span><span class="kw">`</span> [berserk_gutenberg] - revision: 474b7b0a5b</span>
            <span id="cb35-4"><a href="#cb35-4"></a><span class="ex">WARN</span>: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE</span>
            <span id="cb35-5"><a href="#cb35-5"></a><span class="ex">executor</span> <span class="op">&gt;</span>  local (3)</span>
            <span id="cb35-6"><a href="#cb35-6"></a>[<span class="ex">5f</span>/<span class="ex">15f0a5</span>] process <span class="op">&gt;</span> poc15:process_poc15 (3) [<span class="ex">100%</span>] 3 of 3</span>
            <span id="cb35-7"><a href="#cb35-7"></a>[<span class="ex">input2</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/eb/30b10c68b03542373b340e08b2fb88/output.txt]</span>
            <span id="cb35-8"><a href="#cb35-8"></a>[<span class="ex">input1</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/d6/cdd3aa71eab634c017f0eb6e44713c/output.txt]</span>
            <span id="cb35-9"><a href="#cb35-9"></a>[<span class="ex">input3</span>, <span class="op">&lt;</span>...<span class="op">&gt;</span>/diflow/work/5f/15f0a5ed44810731197fcb5f9893e7/output.txt]</span>
            <span id="cb35-10"><a href="#cb35-10"></a></span>
            <span id="cb35-11"><a href="#cb35-11"></a>$ <span class="fu">cat</span> output/input*/output.txt</span>
            <span id="cb35-12"><a href="#cb35-12"></a><span class="ex">11</span></span>
            <span id="cb35-13"><a href="#cb35-13"></a><span class="ex">12</span></span>
            <span id="cb35-14"><a href="#cb35-14"></a><span class="ex">13</span></span></code></pre></div>
            <hr />
            <h1 id="appendix">Appendix</h1>
            <h2 id="caveats-and-tips">Caveats and Tips</h2>
            <h3 id="section"></h3>
            <h3 id="resources">Resources</h3>
            <p>When you run or export with the <code>DockerTarget</code>, resources are automatically added to the running container and stored under <code>/resources</code>. In case of the <code>NativeTarget</code>, this is not the case and since <code>NextFlowTarget</code> uses the <code>NativeTarget</code> it’s the same there. That does not mean that resources specified in <code>functionality.yaml</code> is not available in these cases, we only have to point to them where appropriate.</p>
            <p>The following snippet (from <code>ct/singler</code>) illustrates this:</p>
            <div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a>par =<span class="st"> </span><span class="kw">list</span>(</span>
            <span id="cb36-2"><a href="#cb36-2"></a>  <span class="dt">input =</span> <span class="st">&quot;input.h5ad&quot;</span>,</span>
            <span id="cb36-3"><a href="#cb36-3"></a>  <span class="dt">output =</span> <span class="st">&quot;output.h5ad&quot;</span>,</span>
            <span id="cb36-4"><a href="#cb36-4"></a>  <span class="dt">reference =</span> <span class="st">&quot;HPCA&quot;</span>,</span>
            <span id="cb36-5"><a href="#cb36-5"></a>  <span class="dt">outputField =</span> <span class="st">&quot;cellType&quot;</span>,</span>
            <span id="cb36-6"><a href="#cb36-6"></a>  <span class="dt">pruningMADS =</span> <span class="dv">3</span>,</span>
            <span id="cb36-7"><a href="#cb36-7"></a>  <span class="dt">outputFieldPruned =</span> <span class="st">&quot;celltype-pruned&quot;</span>,</span>
            <span id="cb36-8"><a href="#cb36-8"></a>  <span class="dt">reportOutputPath =</span> <span class="st">&quot;report.md&quot;</span></span>
            <span id="cb36-9"><a href="#cb36-9"></a>)</span>
            <span id="cb36-10"><a href="#cb36-10"></a><span class="co">## VIASH </span><span class="re">END</span></span>
            <span id="cb36-11"><a href="#cb36-11"></a>par<span class="op">$</span>resources_dir &lt;-<span class="st"> </span>resources_dir</span></code></pre></div>
            <p>In other words, <code>resources_dir</code> is automatically created by <code>viash</code> in all current 3 environments. This means that we can point to the <code>report.Rmd</code> file present in the resources like so:</p>
            <div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a>rmarkdown<span class="op">::</span><span class="kw">render</span>(<span class="kw">paste0</span>(par<span class="op">$</span>resources_dir, <span class="st">&quot;/&quot;</span>, <span class="st">&quot;report.Rmd&quot;</span>), <span class="dt">output_file =</span> par<span class="op">$</span>reportOutputPath)</span></code></pre></div>
            <h3 id="default-values">Default values</h3>
            <p>In functionality, no option should have an empty string as value!</p>
            <h3 id="target_image"><code>target_image</code></h3>
            <p>It makes sense to add the <code>target_image</code> attribute in the <code>docker_platform.yaml</code> file. This way, the resulting container image is predictable, rather than an autogenerated tag from <code>viash</code>.</p>
            <h3 id="running-the-docker-setup">Running the Docker setup</h3>
            <p>We don’t have a solution yet for pre-generating the Docker images prior to starting a NXF pipeline. For the moment, we ask the user to run the build script for the Docker targets with the <code>---setup</code> option. This only works locally, it would for instance not work on a different (clean) node or in a Kubernetes cluster.</p>
            <p>We are working on solutions or workarounds for this. Keep you posted!</p>
            <h2 id="open-issues">Open issues</h2>
            <ol type="1">
            <li><p>Multiple files as input for a component: E.g. the concat component uses multiple files to be joined. At the moment this does not seems to be possible.</p></li>
            <li><p>Use of additional input files into a specific component. Some components do not only have input/output but require additional input. How should we map this?</p></li>
            </ol>
            <section class="footnotes" role="doc-endnotes">
            <hr />
            <ol>
            <li id="fn1" role="doc-endnote"><p>https://soft.vub.ac.be/~mathsaey/skitter/<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
            <li id="fn2" role="doc-endnote"><p>https://github.com/weng-lab/krews<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
            <li id="fn3" role="doc-endnote"><p>It <em>is</em> possible in some cases however to manipulate the <code>Channel</code> such that a process is effectively run twice on the same data, but that is a more advanced topic.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
            </ol>
            </section>
            </div>
    </div>
  </div>
</body>
</html>
